# -*- coding: utf-8 -*-
"""Proyek Akhir revisi

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/100Sf6o7zVjyT83O4u_dYzZ6QVpIsPryq

#Membaca Data

Pada tahap ini  akan menghubungkan google colab dengan kaggle sehingga pengambilan dataset dapat lebih cepat dan mudah, hal yang perlu dilakukan adalah sebagai berikut

1. Hubungkan google drive pada google colab
2. Dapatkan Token API dari Kaggle Profile
3. Upload Kaggle API json ke folder pada Google drive
4. Download dataset dari Kaggle API yang diinginkan
5. ekstrak file tersebut
6. read file tersebut menggunakan code dan pastikan path penyimpanan telah sesuai
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""Tahap ini adalah tahap menghubungkan google drive ke google colab"""

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"

"""Tahap ini adalah tahap menghubungakan direktori file API json yang telah di upload ke direktori pada google colab"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/Kaggle

"""Tahap ini adalah tahap mengarahkan file yang di download nanti pada direktrori /content/gdrive/My Drive/Kaggle"""

!kaggle datasets download -d rounakbanik/the-movies-dataset

"""Tahap ini mendownload file yang ada pada kaggle menggunakan API"""

!unzip \*.zip  && rm *.zip

"""Tahap ini adalah mengekstrak file yang ada pada google drive"""

import pandas as pd
import numpy as np


movies_metadata = pd.read_csv('/content/gdrive/MyDrive/Kaggle/movies_metadata.csv')
movies_metadata.head()

"""Tahap ini adalah tahap mengimport libary untuk membaca file dan menampilkan 5 data awal"""

remove_n = 40000
np.random.seed(0)
drop_indices = np.random.choice(movies_metadata.index, remove_n, replace=False)
movies_metadata = movies_metadata.drop(drop_indices)

"""Tahap ini data dikurangi karena spesifikasi laptop yang digunakan tidak kompatibel untuk data yang terlalu banyak

"""

len(movies_metadata)

"""Jumlah data yang digunakan untuk diproeses adalah 5466 baris

#Membersihkan dan Mempersiapkan Data
"""

movies_metadata.info()

"""Pada tahap ini kita dapat melihat informasi tentang DataFrame pada data yang telah dibaca berupa indeks dtype, kolom, nilai non-null, dan penggunaan memori.

Data yang digunakan kali ini tidak memiliki nilai null
"""

movies_metadata.genres.unique()

"""Pada tahap ini melihat unique value dari kolom genre"""

len(movies_metadata.genres.unique())

"""Pada tahap ini melihat panjang dari unique value dari kolom genre"""

judul = movies_metadata['original_title'].tolist()
genre = movies_metadata['genres'].tolist()

print(len(judul))
print(len(genre))

"""pada tahap ini dipilih beberapa kolom berdasarkan data yang dibutuhkan untuk melakukan content based learning berdasarkan genre yaitu judul dan genre """

data = pd.DataFrame({
    'judul': judul,
    'genre': genre
})
data.head()

"""pada tahap ini membuat data yang dipilih menjadi dalam bentuk dataframe sehingga mudah untuk dipersiapkan"""

data.info()

"""Pada tahap ini kita dapat melihat informasi tentang DataFrame pada data yang telah dibaca berupa indeks dtype, kolom, nilai non-null, dan penggunaan memori.

Data yang digunakan kali ini tidak memiliki nilai null sehingga tidak ada data yang kosong yang perlu di isi atau dihapus
"""

value_genre = pd.DataFrame(data['genre'].value_counts().reset_index().values, columns = ['genre', 'count'])
print(len(value_genre))
pd.options.display.max_colwidth = 500
value_genre.head()

"""Pada tahap ini melihat banyaknya data dari setiap unique value berdasarkan genre"""

data = data[data.genre != '[]']

"""Pada tahap ini dilakukan penghapusan data baris genre yang berisi nilai "[]""""

data.genre.unique()

"""Pada tahap ini kembali melihat unique value dari data dengan kolom genre"""

len(data.genre.unique())

"""Pada tahap ini diperlihatkan panjang baris dari data genre yang telah dikurangi data genre yang bervalue "[]""""

len(data)

"""Pada tahap ini diperlihatkan banyak baris dari data yang digunakan"""

data = data.drop_duplicates('judul')
len(data)

"""Pada tahap ini dihapus baris data yang sama berdasarkan kolom judul dan melihat kembali panjang datanya"""

data.shape

"""Pada tahap ini diperlihatkan ukuran dari matriks data yang digunakan"""

data.reset_index()
data.head()

"""Pada tahap ini dilakukan indeks ulang pada data yang digunakan agar penomoran berurutan"""

def str_to_list(x):
    genre_list = []
    for item in eval(x):
        genre_list.append(item['name'])
    return genre_list

data.genre = data.genre.apply(str_to_list)

"""Pada tahap ini diambil value name dari genre dari data genre yang berisi id dan name, sehingga data genre dapat terlihat lebih jelas """

judul = data['judul'].tolist()
genre = data['genre'].tolist()

print(len(judul))
print(len(genre))

"""Pada tahap ini dilakukan konversi data series menjadi list"""

data = pd.DataFrame({
    'judul': judul,
    'genre': genre
})
data.head()

"""Pada tahap ini dibuat dictionary untuk menentukan pasangan key-value pada data 
judul dan genre
"""

genre = [str (item) for item in data['genre']]

genre = [item for item in genre if not isinstance(item, int)]

"""Pada tahap ini membuat data didalam genre menjadi string karena sebelumnya data didalam genre berupa series dan masih terdapat data bertipe integer sehingga tidak bisa diproses pada tahap selanjutnya

#Feature Enggenering
"""

import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter

word_could_dict=Counter(genre)
wordcloud = WordCloud(width = 2000, height = 1000).generate_from_frequencies(word_could_dict)

plt.figure(figsize=(15,8))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()

"""Pada tahap ini diperlihatkan genre pada seluruh data dengan ukuran berdasarkan genre yang paling banyak muncul menggunakan plot word cloud"""

from sklearn.feature_extraction.text import CountVectorizer 
 
# Inisialisasi CountVectorizer
tf = CountVectorizer()
 
# Melakukan perhitungan idf pada data genre
tf.fit(genre) 

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

"""Pada tahap ini membangun sistem rekomendasi sederhana berdasarkan genre yang ada pada setiap movies."""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(genre) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Pada tahap ini di lakukan proses fit dan transformasi ke dalam bentuk matriks"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""Pada tahap ini bertujuan Untuk menghasilkan vektor tf-idf dalam bentuk matriks menggunakan fungsi todense()."""

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.judul
).sample(22, axis=1).sample(10, axis=0)

"""Pada tahapini kita melihat matriks tf-idf untuk beberapa judul film dan kategori genre

#Latih Model dengan cosine similarity
"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""Pada tahap ini dihitung cosine similarity dataframe tfidf_matrix yang kita peroleh pada tahapan sebelumnya"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['judul'], columns=genre)
print('Shape:', cosine_sim_df.shape)
 

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Pada tahap ini diperlihatkan matriks kesamaan setiap judul dengan menampilkan judul film dalam 5 sampel kolom (axis = 1) dan 10 sampel baris (axis=0).

#Uji Model
"""

indices = pd.Series(index = data['judul'], data = data.index).drop_duplicates()
indices.head()

"""Pada tahap dilakukan indikasi dan diperlihatkan judul film berdasarkan urutan dari data"""

def get_recommendations(judul, cosine_sim = cosine_sim,items=data[['judul','genre']]):
    # Mengambil indeks dari judul film yang telah didefinisikan sebelumnnya
    idx = indices[judul]
    
    # Mengambil skor kemiripan dengan semua judul film 
    sim_scores = list(enumerate(cosine_sim[idx]))
    
    # Mengurutkan film berdasarkan skor kemiripan
    sim_scores = sorted(sim_scores, key = lambda x : x[1], reverse = True)
    
    # Mengambil 10 skor kemiripan dari 1-10 karena urutan 0 memberikan indeks yang sama dengan judul film yang diinput
    sim_scores = sim_scores[1:11]
    
    # Mengambil judul film dari skor kemiripan
    movie_indices = [i[0] for i in sim_scores]
    
    # Mengembalikan 10 rekomendasi judul film dari kemiripan skor yang telah diurutkan dan menampilkan genre dari 10 rekomendasi film tersebut
    return pd.DataFrame(data['judul'][movie_indices]).merge(items)

"""Pada tahap ini dibuat fungsi untuk memanggil 10 rekomendasi film berdasarkan judul yang di input"""

data[data.judul.eq('The American President')]

"""Pada tahap ini dilakukan cek apakah judul film ada pada data atau tidak"""

rekomendasi = pd.DataFrame(get_recommendations('The American President'))
rekomendasi

"""Pada tahap ini ditampilkan 10 rekomendasi film dari judul yang telah di input"""

value = pd.DataFrame(rekomendasi['genre'].value_counts().reset_index().values, columns = ['genre', 'count'])
value.head()

"""Pada tahap ini melihat jumlah genre dari rekomendasi"""

TP = 10 #jumlah prediksi benar untuk genre yang mirip atau serupa
FP = 0 #jumlah prediksi salah untuk genre yang mirip atau serupa

Precision = TP/(TP+FP)
print("{0:.0%}".format(Precision))

"""Pada tahap ini digunakan metrik precision untuk melihat akurasi"""